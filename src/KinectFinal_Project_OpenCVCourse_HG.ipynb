{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Final Project__\n",
    "\n",
    "#### Python for Computer Vision with OpenCV \n",
    "\n",
    "#### Herb Guzman\n",
    "#### UTSA\n",
    "#### Fall 2019\n",
    "\n",
    "Project Assignment: Create a program that can detect a hand, segment the had, and count the number of fingers being held up.\n",
    "This is designed to work with most webcams, but for this demonstration an Azure Kinect DK device was used.\n",
    "\n",
    "###### Strategie for Counting Fingers\n",
    "\n",
    "-  Grab a Range of Interest (ROI)\n",
    "-  Calculate a running average background value for 60 frames of video (i.e. if rate is 30 frames/sec, then 2 seconds)\n",
    "-  Once the average value has been found, the hand can enter the ROI\n",
    "-  Once the hand is in the ROI, detect the change and apply thresholding to isolate the hand and hand segment\n",
    "-  With the hand detected in the ROI, use a Convex Hull to draw a polygon around the hand\n",
    "-  With the polygon outlined, calculate the center of the hand\n",
    "-  Next, use the center of the hand to calculate the angle of the outer points to infer the finger count\n",
    "   the polygon will have points at each finger.\n",
    "-  Based on the distance from the center, determine if the finger is extended or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# Initialize the background prior to sensing anything\n",
    "background = None\n",
    "\n",
    "# Initialize the accumulated weight to some middle value\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "# Default definition for region_of_interest = ROI\n",
    "# Corners of the rectangle on the screen\n",
    "# THE INITIAL ROI MAY NEED ADJUSTMENTS\n",
    "\n",
    "ROI_Top = 30\n",
    "ROI_Bottom = 400\n",
    "ROI_Right = 500\n",
    "ROI_Left = 800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION FOR UPDATING A RUNNING AVERAGE OF THE BACKGROUND VALUES IN\n",
    "# A RANGE OF INTEREST (ROI).\n",
    "# This function will allow to detect new objects (the hand) entering and leaving the ROI\n",
    "\n",
    "def calc_accum_avg(frame, accumulated_weight):\n",
    "    \n",
    "    global background\n",
    "    \n",
    "    # For the first time...\n",
    "    # if the background is none, set the background\n",
    "    # as a copy of the frame being passed into this function\n",
    "    #\n",
    "    # Else,\n",
    "    # if there is something other than none assigned to the \n",
    "    # background: use the cv2 function accumulateWeighted\n",
    "    # where in you pass the source (src), destination (dst) and an\n",
    "    # alpha value.  This function calculates the weighted sum\n",
    "    # of the source image and the accumulator destination; then,\n",
    "    # the destination becomes a running average of a frame sequence.\n",
    "    # This function essentially accumulates the weight based on the running \n",
    "    # average\n",
    "    # Note that there is no returned value from the accumulateWeighted function\n",
    "    # we are only doing an update with the accumulated weight\n",
    "    if background is None: \n",
    "        background = frame.copy().astype('float')\n",
    "        return None\n",
    "    \n",
    "    cv2.accumulateWeighted(frame,background,accumulated_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION FOR THRESHOLDING AND CONTOURING\n",
    "# Segment the hand region in the frame's ROI\n",
    "# Using thresholding\n",
    "# Create a \"white\" hand and create a countour around that.\n",
    "# Use a minimum value of 25 for a binary threshold\n",
    "# This will be affected by the uniforminty and colors in the background\n",
    "# THE THRESHOLD MAY NEED ADJUSTMENT. THIS THRESHOLD VALUE CAN BE USED\n",
    "# TO CONTROL THE BACKGROUND NOISE\n",
    "#\n",
    "# So, threshold_min is the minimum value and is set to 25\n",
    "# The max value can be set to 255\n",
    "#\n",
    "def segment(frame,threshold_min=30):\n",
    "\n",
    "    # (1) Calculate the absolute difference between the background and\n",
    "    # the frame passed in to the function\n",
    "    #\n",
    "    # (2) Next apply a threshold to this image\n",
    "    #\n",
    "    # (3) Next, grab the external contours from the image:\n",
    "    # To do this use the findContours function of cv2 using a copy of\n",
    "    # the thresholded image and obtain the EXTERNAL contours of this image\n",
    "    # Use the \"CHAIN_APPROX_SIMPLE\" as the method used to calculate the contours\n",
    "    #\n",
    "    # (4) Make sure the length of the contours is not zero; that is, the\n",
    "    # algorithm found some contours. If the contour length is not zero,\n",
    "    # then the largest external contour is the hand.  This means that if\n",
    "    # another long object such as a pencil or marker is in the ROI, this \n",
    "    # will confuse this function.\n",
    "    #\n",
    "    diff = cv2.absdiff(background.astype('uint8'),frame)\n",
    "    \n",
    "    ret,thresholded_image = cv2.threshold(diff,threshold_min,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    image,contours,hierarchy = cv2.findContours(thresholded_image.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        # Assuming the largest external contour in the ROI is the hand\n",
    "        # Need to use a \"key\" to handle the numpy array structure.\n",
    "        # This will grab the contour with the largest amount of area.\n",
    "        # This will help discriminate with smaller contours in the background.\n",
    "        hand_segment = max(contours,key=cv2.contourArea)\n",
    "        \n",
    "        return (thresholded_image,hand_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION FOR FINGER COUNTING USING A CONVEX HULL METHOD\n",
    "# This function counts the fingers held up using the Convex Hull method\n",
    "# to draw a polygon connecting the points around the most external\n",
    "# points in a frame.  The way a Convex Hull works is that it will \n",
    "# draw a polygon connect the most external points in a data set.\n",
    "# The way the logic will work for this function is that if the \n",
    "# length from the hand's center to each outer point is low, then the\n",
    "# function will assume the finger is retracted.  Otherwise, if the\n",
    "# length of approximately the same as the other fingers, then the finger\n",
    "# will be assumed to be extended.\n",
    "# Also, the function will need to account for the points coming from the wrist.\n",
    "# The logic for this process is as follows:\n",
    "# \n",
    "# 1. Calculate the most extreme points, max top, max bottom, max left, max right.\n",
    "# 2. Use their intersection to estimate the center of the hand\n",
    "# 3. Calculate the distance from the point furthest away from the center\n",
    "# 4. Use that distance to create a circle\n",
    "# 5. Any points outside the circle or close to the edge of the circle will\n",
    "#    be assumed to be extended fingers.\n",
    "\n",
    "def count_fingers(thresholded_image,hand_segment):\n",
    "    \n",
    "    # Calculate the convex hull for the hand segment contour\n",
    "    conv_hull = cv2.convexHull(hand_segment)\n",
    "    \n",
    "    # Obtain the extreme points from the Hull (top, bottom, right and left)\n",
    "    # Because of the format of the convex hull output, we need the following steps:\n",
    "    # According to the OpenCV on contour approximation and Convex Hull using and enclosing polygon\n",
    "    \n",
    "    # Obtain the most extreme Top point...\n",
    "    # grab the first index of the minimum argument of this vector\n",
    "    # Obtain this as a tuple and assign it to the variable \"top\"\n",
    "    # Repeat this idea for the bottom, left, and right-most points:\n",
    "    \n",
    "    # Debugging code\n",
    "    # print (\"Val of conv_hull :\",conv_hull)\n",
    "    \n",
    "    top =    tuple( conv_hull[conv_hull[:, :, 1].argmin()][0] )    # Min\n",
    "    bottom = tuple( conv_hull[conv_hull[:, :, 1].argmax()][0] )    # Max\n",
    "    left =   tuple( conv_hull[conv_hull[:, :, 0].argmin()][0] )    # Min\n",
    "    right =  tuple( conv_hull[conv_hull[:, :, 0].argmax()][0] )    # Max\n",
    "    \n",
    "    # Now, calculate the \"center\" of the hand\n",
    "    # Note that index 0 are the x coordinates and index 1 are the y coordinates\n",
    "    # Divide by 2 using two // to make sure the result is an integer\n",
    "    \n",
    "    cX = (left[0] + right[0]) // 2\n",
    "    cY = (top[1] + bottom[1]) // 2\n",
    "    \n",
    "    # Distance calculation using the sklearn pairwise function\n",
    "    # Calculate the euclidean distance between the center and the four outer points\n",
    "    # Provide a list of the points we need to calculate a distance, call it 'Y'\n",
    "    # Make sure to only grab the very first item returned (i.e. 0)\n",
    "    # This returns all the distances\n",
    "\n",
    "    # Debugging code\n",
    "    # print (\"Val of left :\",left)\n",
    "    # print (\"Val of right :\",right)\n",
    "    # print (\"Val of top :\",top)\n",
    "    # print (\"Val of bottom :\",bottom)\n",
    "    #\n",
    "    # print (\"Val of cX :\",cX)\n",
    "    # print (\"Val of cY :\",cY)\n",
    "    \n",
    "    distance = pairwise.euclidean_distances([(cX,cY)],Y=[left,right,top,bottom])[0]\n",
    "    \n",
    "    # Now, determine the maximum distance, which is really the only distances we need\n",
    "    max_distance = distance.max()\n",
    "    \n",
    "    # Now, calculate a circle with a radius of 90% of \"max_distance\"\n",
    "    # THE 90% adjustment value can be adjusted in case the hand has very short fingers\n",
    "    # Make this value an integer; also calculate the circumference of the circle\n",
    "    radius = int(0.75* max_distance)\n",
    "    circumference = (2 * np.pi * radius)\n",
    "    \n",
    "    # Now, create an ROI\n",
    "    # First initialize a place holder of the same structure as the thresholded_image with zeros as content\n",
    "    # Only the X and Y of the thresholded image; we do not need the color channels\n",
    "    # This data type is an 8-bit integer\n",
    "    circular_roi = np.zeros(thresholded_image.shape[:2], dtype='uint8')\n",
    "    \n",
    "    # Now 'draw' the circular ROI using cv2\n",
    "    # Use the circular_roi as the image for the circle\n",
    "    # Use cX and cY for the center points, provide the radius obtained above\n",
    "    # use a color of 255 and the thickness of the circle as 10 pixels\n",
    "    cv2.circle(circular_roi,(cX,cY),radius,255,10)\n",
    "    \n",
    "    # Use bitwise AND with the circle_roi image as a mask and the thresholded_image\n",
    "    circular_roi = cv2.bitwise_and(thresholded_image,thresholded_image,mask=circular_roi)\n",
    "    \n",
    "    # Now grab all the EXTERNAL contours in the resulting circular_roi, but use a copy of the circular_roi for now\n",
    "    # FOR THE METHOD, set it equal to chain_approx_none\n",
    "    image,contours,hierarchy = cv2.findContours(circular_roi.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Finally, count the number of points/fingers outside the circle\n",
    "    \n",
    "    # Initialize the [finger] count to zero\n",
    "    count = 0\n",
    "    \n",
    "    # For every contour in the list of contours, grab the bounding box of the contour\n",
    "    # with the following conditions:\n",
    "    # (1) The contour region is not at the bottom of the hand (discriminate the wrist and lower arm)\n",
    "    #     if it is too far below the center of the hand\n",
    "    for cnt in contours:\n",
    "        \n",
    "        (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "    \n",
    "        # Discriminate the wrist: center y plus the 25% of center y distance is greater than the height plus the y value\n",
    "        # for a given bouding rectangle for the corresponding contour\n",
    "        out_of_wrist = (cY + (cY*0.25)) > (y+h)\n",
    "    \n",
    "        # Check that the number of points around the contour does not exceed the 25% of the circumference of the circular region\n",
    "        # of interest.  Otherwise, we could be including points completely outside the hand itself.\n",
    "        # So, define some limit points.\n",
    "        limit_points = ((circumference*0.25) > cnt.shape[0])\n",
    "        \n",
    "        # Now, test for the conditions:\n",
    "        # (2) If it is outside of the wrist and is not one of the limit points, \n",
    "        #     then the point actually belongs to a finger and we can increment the finger count\n",
    "        if out_of_wrist and limit_points:\n",
    "            count += 1\n",
    "        \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-772ae763568f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Create a copy of the frame to use in the functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mframe_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Grab the ROI from the original frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# MAIN PROGRAM\n",
    "#\n",
    "# This program uses the functions defined above to capture live video from a person's hand and detect how many\n",
    "# fingers are shown on the screen.\n",
    "\n",
    "# Grab the video from the default camera\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "# Accumulate 60 frames for background\n",
    "num_frames = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Create a copy of the frame to use in the functions\n",
    "    frame_copy = frame.copy()\n",
    "    \n",
    "    # Grab the ROI from the original frame\n",
    "    # using the top, bottom, left, and right specifications defined above\n",
    "    # then create a grayscale version of roi; convert from BGR to GRAY\n",
    "    # Recall than using OpenCV, the video frames are BGR when first loaded\n",
    "    roi = frame[ROI_Top:ROI_Bottom,ROI_Right:ROI_Left]\n",
    "    gray = cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Next, apply a Gaussian blur to the grayscale image to help average all the values\n",
    "    # use a 7x7 kernel and \n",
    "    gray = cv2.GaussianBlur(gray,(7,7),0)\n",
    "    \n",
    "    # Now, define the number of frames to be used for the ROI definition\n",
    "    if num_frames < 60:\n",
    "        calc_accum_avg(gray,accumulated_weight)\n",
    "        \n",
    "        # DETERMINE ROI (ALSO WINDOW 1 - OVERALL LIVE STREAM)\n",
    "        # While the background is being calculated, show a message\n",
    "        # noting that the background is being calculated\n",
    "        if num_frames <= 59:\n",
    "            cv2.putText(frame_copy,'WAIT, GETTING BACKGROUND',(200,300),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow('Herb''s Finger Count Program',frame_copy)\n",
    "    else:\n",
    "        \n",
    "        # HAND SEGMENT DETECTION AND CALCULATION\n",
    "        # Otherwise, scan the hand, determine the segments passing the grayscale image:\n",
    "        \n",
    "        # First segment the hand region\n",
    "        # The way the segment function was defined above, we cannot use tupple unpacking\n",
    "        # if there is no hand, the parameter returned from segment is just \"none\"\n",
    "        # So, we need to check for this first\n",
    "        hand = segment(gray)\n",
    "        \n",
    "        # See if the hand was actually detected as an external contour\n",
    "        # then unpack.\n",
    "        # This means that if there is actually a hand detected, the information returned\n",
    "        # by the segment function will actually contain a tuple; so, now we can use\n",
    "        # tuple unpacking\n",
    "        if hand is not None:\n",
    "            thresholded_image, hand_segment = hand\n",
    "            \n",
    "            # WINDOW 1\n",
    "            # Highlight the hand in the real image.\n",
    "            # That is, draw the contours around the real hand in the live stream\n",
    "            cv2.drawContours(frame_copy,[hand_segment+(ROI_Right,ROI_Top)],-1,(255,0,0),5)\n",
    "            \n",
    "            # Now, count the fingers\n",
    "            fingers = count_fingers(thresholded_image, hand_segment)\n",
    "            \n",
    "            # Display the count on the live stream\n",
    "            cv2.putText(frame_copy,str(fingers),(200,100),cv2.FONT_HERSHEY_SIMPLEX,3,(0,255,0),6)\n",
    "            \n",
    "            # WINDOW 2\n",
    "            # Also show the thresholded image\n",
    "            # create a new window\n",
    "            # This window helps to view the process and decide if the threshold minimum value needs tuning\n",
    "            # threshold_min = 25 at the start\n",
    "            cv2.imshow('Thresholed Image',thresholded_image)\n",
    "            \n",
    "    # Draw a rectangle of the ROI\n",
    "    cv2.rectangle(frame_copy,(ROI_Left,ROI_Top),(ROI_Right,ROI_Bottom),(0,255,0),2)\n",
    "    \n",
    "    # Increment the number of frames\n",
    "    num_frames += 1\n",
    "    \n",
    "    # Show the finger count on the live-stream window\n",
    "    cv2.imshow('Herb''s Finger Count Program',frame_copy)\n",
    "    \n",
    "    # Add a means to exit the program using the escape key (27)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "# Release the camera stream and close all the windows if the ESC key is pressed\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
